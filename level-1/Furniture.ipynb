{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IyY1OLm90na",
        "outputId": "e6e847ee-8c52-482c-f25b-6e2874daaf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.9.86.109)] [Conn\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease 15.6 kB/88.7 kB 18%] [3 InRelease 22.9 kB/88.7 kB 26%] [Waiting\r0% [1 InRelease gpgv 242 kB] [2 InRelease 15.6 kB/88.7 kB 18%] [3 InRelease 22.\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 18.5 kB/88.7 kB 21%] [3 InRelease 31.\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 21.4 kB/88.7 kB 24%] [3 InRelease 40.\r0% [1 InRelease gpgv 242 kB] [2 InRelease 69.2 kB/88.7 kB 78%] [Waiting for hea\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Conne\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,992 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,546 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,424 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,324 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n",
            "Fetched 11.5 MB in 2s (5,508 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbsr_FuYAJWk",
        "outputId": "9814fc19-10f7-4e18-db39-0028ba7be179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-09 18:44:40--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  1.66MB/s    in 0.5s    \n",
            "\n",
            "2022-10-09 18:44:41 (1.66 MB/s) - ‘postgresql-42.2.9.jar’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GB1wvfd1AcFI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TFKUxFFAyW0",
        "outputId": "655895b5-b675-4295-c247-edf9c7856ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   24509695|R3VR960AHLFKDV|B004HB5E0E|     488241329|Shoal Creek Compu...|       Furniture|          4|            0|          0|   N|                Y|... desk is very ...|This desk is very...| 2015-08-31|\n",
            "|         US|   34731776|R16LGVMFKIUT0G|B0042TNMMS|     205864445|Dorel Home Produc...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|          Great item| 2015-08-31|\n",
            "|         US|    1272331|R1AIMEEPYHMOE4|B0030MPBZ4|     124663823|Bathroom Vanity T...|       Furniture|          5|            1|          1|   N|                Y|          Five Stars|Perfect fit for m...| 2015-08-31|\n",
            "|         US|   45284262|R1892CCSZWZ9SR|B005G02ESA|     382367578|Sleep Master Ulti...|       Furniture|          3|            0|          0|   N|                Y|         Good enough|We use this on a ...| 2015-08-31|\n",
            "|         US|   30003523|R285P679YWVKD1|B005JS8AUA|     309497463|1 1/4\" GashGuards...|       Furniture|          3|            0|          0|   N|                N|Gash Gards for da...|The product is fi...| 2015-08-31|\n",
            "|         US|   18311821| RLB33HJBXHZHU|B00AVUQQGQ|     574537906|Serta Bonded Leat...|       Furniture|          5|            0|          0|   N|                Y|          Five Stars|Love this product...| 2015-08-31|\n",
            "|         US|   42943632|R1VGTZ94DBAD6A|B00CFY20GQ|     407473883|Prepac Shoe Stora...|       Furniture|          5|            2|          2|   N|                Y|   I love this bench|I love this bench...| 2015-08-31|\n",
            "|         US|   43157304|R168KF82ICSOHD|B00FKC48QA|     435120460|HomCom PU Leather...|       Furniture|          5|            0|          0|   N|                Y|Great storage cap...|Have had this for...| 2015-08-31|\n",
            "|         US|   51918480|R20DIYIJ0OCMOG|B00N9IAL9K|     356495985|  Folding Step Stool|       Furniture|          5|            0|          0|   N|                Y|This is the best ...|This is the best ...| 2015-08-31|\n",
            "|         US|   14522766| RD46RNVOHNZSC|B001T4XU1C|     243050228|Ace Bayou Adult V...|       Furniture|          5|            0|          0|   N|                Y|    great for price!|    my son loves it!| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkFiles\n",
        "# Load in the selected csv from S3 into a DataFrame\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "# Creating the dataframe\n",
        "furniture_df = spark.read.csv(SparkFiles.get(\"amazon_reviews_us_Furniture_v1_00.tsv.gz\"), inferSchema=True, sep='\\t', timestampFormat=\"mm/dd/yy\", header =True)\n",
        "furniture_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZGQsdB6Crt3",
        "outputId": "e4dbfc68-ee6f-4870-d9f1-5605825dfa70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "792113\n"
          ]
        }
      ],
      "source": [
        "# Count of dataframe records\n",
        "print(furniture_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m367ofUKOyht",
        "outputId": "4ccd4dfd-970f-4487-9613-7ea65d74a9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "791971\n"
          ]
        }
      ],
      "source": [
        "# Dropping the NA ones and displaying new record count\n",
        "furniture_df = furniture_df.dropna()\n",
        "print(furniture_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FAKhotiVZNk",
        "outputId": "43fdcb20-9627-4bb3-cd20-3332aa0a4eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "791971\n"
          ]
        }
      ],
      "source": [
        "# Dropping the duplicate ones and displaying new record count\n",
        "furniture_df = furniture_df.dropDuplicates()\n",
        "print(furniture_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Cb8JbpZsDR",
        "outputId": "211c3b52-b19f-4aeb-8c89-172568c092dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- marketplace: string (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_parent: integer (nullable = true)\n",
            " |-- product_title: string (nullable = true)\n",
            " |-- product_category: string (nullable = true)\n",
            " |-- star_rating: integer (nullable = true)\n",
            " |-- helpful_votes: integer (nullable = true)\n",
            " |-- total_votes: integer (nullable = true)\n",
            " |-- vine: string (nullable = true)\n",
            " |-- verified_purchase: string (nullable = true)\n",
            " |-- review_headline: string (nullable = true)\n",
            " |-- review_body: string (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Schema\n",
        "furniture_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJybuGqfQA2k",
        "outputId": "a51d1f95-c53e-4c79-9482-2d8420f6f6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|     review_id|customer_id|product_id|product_parent|review_date|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|R102J678JN8OQL|   46476285|B008OS1WGQ|     991978353| 2013-07-05|\n",
            "|R102WTX7GH5XZJ|   28589116|B00DGEPIPO|     241314063| 2013-12-12|\n",
            "|R105DQG52MW5S9|   51878818|B004Y6G7QC|     216229139| 2012-10-08|\n",
            "|R107GJAMGANOJA|   52387168|B003QVDHRS|     957908300| 2014-11-23|\n",
            "|R10A1UPXAUZ8W3|   36143353|B000WWAR22|     938792177| 2011-08-29|\n",
            "|R10BV8UMGA6599|    9740769|B000KK7Y3Q|     478396916| 2015-08-12|\n",
            "|R10E2K84D6CKQ1|   43778765|B00EZ5TB4W|     848089547| 2015-01-11|\n",
            "|R10EJFWP9F3C42|   11616909|B005CR11A4|     643469497| 2013-04-26|\n",
            "|R10F4GS24G0HBE|    3269876|B008OTSIY4|     981686694| 2015-04-01|\n",
            "|R10GED5OITNO3Z|   15345890|B005O9Z1RE|     399691007| 2013-08-17|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Selecting the required columns for the review dataframe and displaying the first 10 records\n",
        "review_id_df = furniture_df.select(['review_id', 'customer_id', 'product_id', 'product_parent', 'review_date'])\n",
        "review_id_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf97Oro9VOv9",
        "outputId": "d3a91ddd-1b60-49d8-ec70-3c2841d952b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_parent: integer (nullable = true)\n",
            " |-- review_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using different data types required for the Review dataframe\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import StringType,BooleanType,DateType,IntegerType\n",
        "review_id_df = review_id_df.withColumn(\"review_id\",col(\"review_id\").cast(StringType())) \\\n",
        "    .withColumn(\"customer_id\",col(\"customer_id\").cast(IntegerType())) \\\n",
        "    .withColumn(\"product_id\",col(\"product_id\").cast(StringType())) \\\n",
        "    .withColumn(\"product_parent\",col(\"product_parent\").cast(IntegerType())) \\\n",
        "    .withColumn(\"review_date\",col(\"review_date\").cast(DateType()))\n",
        "\n",
        "review_id_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc51VsfqsyZa",
        "outputId": "d7f2d89b-e7d5-4b23-83de-d666f18d802d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|product_id|       product_title|\n",
            "+----------+--------------------+\n",
            "|B008OS1WGQ|Prepac Series 9 D...|\n",
            "|B00DGEPIPO|8.7' x 12' Flowin...|\n",
            "|B004Y6G7QC|Coaster Furniture...|\n",
            "|B003QVDHRS|Track Ceiling Pot...|\n",
            "|B000WWAR22|Spider Web Key Ho...|\n",
            "|B000KK7Y3Q|1 X Unique 72\" Hi...|\n",
            "|B00EZ5TB4W|Sleep Innovations...|\n",
            "|B005CR11A4|Skid-resistant Ca...|\n",
            "|B008OTSIY4|Flash Furniture H...|\n",
            "|B005O9Z1RE|Designer Modern L...|\n",
            "+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creating records for products dataframe\n",
        "products_df = furniture_df.select(['product_id', 'product_title'])\n",
        "products_df.dropDuplicates(['product_id'])\n",
        "products_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw7nvQ9Rt5Qx",
        "outputId": "ca478860-7a31-4d17-fbe5-6cb94a5f3bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_title: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "products_df = products_df.withColumn(\"product_id\",col(\"product_id\").cast(StringType())) \\\n",
        "    .withColumn(\"product_title\",col(\"product_title\").cast(StringType()))\n",
        "\n",
        "products_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2M6nsssyD7H",
        "outputId": "2b47fbb0-46e4-48da-c461-9b43403846d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|   46476285|\n",
            "|   28589116|\n",
            "|   51878818|\n",
            "|   52387168|\n",
            "|   36143353|\n",
            "|    9740769|\n",
            "|   43778765|\n",
            "|   11616909|\n",
            "|    3269876|\n",
            "|   15345890|\n",
            "+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "customers_df = furniture_df.select(['customer_id'])\n",
        "customers_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBBBTZJjz1If",
        "outputId": "052447f4-ecc6-4eb5-c376-bdb3db7ca6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|customer_id|count|\n",
            "+-----------+-----+\n",
            "|   50099399|    3|\n",
            "|   14866125|    1|\n",
            "|   19225480|    1|\n",
            "|    5901466|    1|\n",
            "|   39976700|    2|\n",
            "|   37762729|    1|\n",
            "|   50579579|    1|\n",
            "|    5937990|    2|\n",
            "|   45831934|    1|\n",
            "|   10134614|    1|\n",
            "+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Counting records for specific customer IDs \n",
        "customers_df = customers_df.groupby('customer_id').count()\n",
        "customers_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCBg1Fgb00XR",
        "outputId": "f2496a44-1d99-4314-81a4-1982aebf2061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|customer_count|\n",
            "+-----------+--------------+\n",
            "|   50099399|             3|\n",
            "|   14866125|             1|\n",
            "|   19225480|             1|\n",
            "|    5901466|             1|\n",
            "|   39976700|             2|\n",
            "|   37762729|             1|\n",
            "|   50579579|             1|\n",
            "|    5937990|             2|\n",
            "|   45831934|             1|\n",
            "|   10134614|             1|\n",
            "+-----------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "customers_df = customers_df.withColumnRenamed('count', 'customer_count')\n",
        "customers_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKKi89CL1Xj0",
        "outputId": "a519de9c-5804-405d-c7f1-d546f886986a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- customer_count: integer (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "customers_df = customers_df.withColumn(\"customer_id\",col(\"customer_id\").cast(IntegerType())) \\\n",
        "    .withColumn(\"customer_count\",col(\"customer_count\").cast(IntegerType()))\n",
        "\n",
        "customers_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgkFUuwB2Q27",
        "outputId": "c3b5e0ab-db9c-4f2f-b141-c2a4fd8e7f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R102J678JN8OQL|          5|            1|          1|   N|\n",
            "|R102WTX7GH5XZJ|          5|            0|          0|   N|\n",
            "|R105DQG52MW5S9|          1|            5|          5|   N|\n",
            "|R107GJAMGANOJA|          5|            0|          0|   N|\n",
            "|R10A1UPXAUZ8W3|          5|            0|          0|   N|\n",
            "|R10BV8UMGA6599|          5|            0|          0|   N|\n",
            "|R10E2K84D6CKQ1|          5|            3|          3|   N|\n",
            "|R10EJFWP9F3C42|          5|            0|          0|   N|\n",
            "|R10F4GS24G0HBE|          1|            0|          1|   N|\n",
            "|R10GED5OITNO3Z|          5|            3|          3|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Creating the vine dataframe with the required fields\n",
        "vine_table_df = furniture_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n",
        "vine_table_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGcL6iFs2_2a",
        "outputId": "9a9cae31-e719-490f-dff3-2578d7480734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- star_rating: integer (nullable = true)\n",
            " |-- helpful_votes: integer (nullable = true)\n",
            " |-- total_votes: integer (nullable = true)\n",
            " |-- vine: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vine_table_df = vine_table_df.withColumn(\"review_id\",col(\"review_id\").cast(StringType())) \\\n",
        "    .withColumn(\"star_rating\",col(\"star_rating\").cast(IntegerType())) \\\n",
        "    .withColumn(\"helpful_votes\",col(\"helpful_votes\").cast(IntegerType())) \\\n",
        "    .withColumn(\"total_votes\",col(\"total_votes\").cast(IntegerType())) \\\n",
        "    .withColumn(\"vine\",col(\"vine\").cast(StringType()))\n",
        "\n",
        "vine_table_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l_TxqfiB4Rhz"
      },
      "outputs": [],
      "source": [
        "# RDS configuration - as required, changed the values, so this will fail now when I run it. \n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://my-amazon-endpoint:5432/postgres\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": \"of-course-this-is-not-my-real-password\", \n",
        "          \"driver\":\"org.postgresql.Driver\"} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LfjSpM-k_MdB",
        "outputId": "eeeb984d-8446-483c-b9f9-03b84aff7032"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d35859fcf602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# JDBC write tables (won't work as connection above will fail with the dummy connection details)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview_id_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'review_id_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mproducts_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'products'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcustomer_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvine_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vine_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop2.7/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o198.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:292)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:211)\n\tat org.postgresql.Driver.makeConnection(Driver.java:458)\n\tat org.postgresql.Driver.connect(Driver.java:260)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.net.UnknownHostException: my-amazon-endpoint\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:75)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:91)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:192)\n\t... 50 more\n"
          ]
        }
      ],
      "source": [
        "# JDBC write tables (won't work as connection above will fail with the dummy connection details)\n",
        "review_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)\n",
        "products_table_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)\n",
        "customer_table_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)\n",
        "vine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}